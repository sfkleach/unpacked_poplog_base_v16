% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%     Extracts from the book "Natural Language Processing in POP-11"    %
%                      published by Addison Wesley                      %
%        Copyright (c) 1989, Gerald Gazdar & Christopher Mellish.       %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

Words, rules and structures

We have represented our illustrative tree graphically, but such
diagrams are not, given the limitations of present computers, a
convenient data structure to use for NLP.  The simplest way to handle
trees is to manipulate them as lists, where the first element is the
root category and subsequent elements are the daughter subtrees in
order of occurrence.  Thus, our tree would be represented as follows
in POP-11:

    [S [NP MediCenter][VP [V employed][NP nurses]]]

The general principle is that a tree is represented by a list whose
first element is the top label and whose subsequent elements are the
immediate subtrees in order.  These elements are then themselves
lists, representing the subtrees according to the same convention.  In
this scheme, a leaf node of a tree (here, an English word) is simply
represented by itself.  This kind of list would appear in a 'pretty-
printed' format as follows:

    [S
        [NP MediCenter]
        [VP
            [V employed]
            [NP nurses ]]]

Grammars in POP-11 and random generation

In POP-11 programs, we will represent a grammar by a list of
structures, one for each rule, and store the current grammar in a
global variable called rules.  Each rule is represented by a list of
items.  The first represents the LHS of the rule, while the rest
represent the items on the RHS in sequence.  In rules, English words
are represented by the corresponding POP-11 words and grammatical
categories are put inside lists to distinguish them from words.  In
grammars like Grammar1, where the only relevant feature for categories
is cat, we need not explicitly mention the feature names in rules, and
so, in writing rules for this kind of grammar, we can specify the                     
category that has cat S simply by [S], for instance.  Note that,
although we will adopt this convention for rules, we will still build
parse trees as described earlier - that is, with bare cat values like
S, rather than lists like [S], as labels.  Here is a representation of
Grammar1 in POP-11 (also in lib cfpsgram):

       [[[S] [NP] [VP]]
        [[VP] [V]]
        [[VP] [V] [NP]]
        [[V] died]
        [[V] employed]
        [[NP] nurses]
        [[NP] patients]
        [[NP] MediCenter]
        [[NP] Dr Chan]] -> rules;

Notice that we have included the lexicon in the set of rules without
making any explicit distinction.  Thus, for instance, we have
interpreted the lexical entry:

    Word employed:
         <cat> = V.

simply as another way to specify the rule

    V -> employed

One advantage of this approach is that it allows us to deal with 'Dr
Chan' as a sequence of two words in a natural way.  There are a number
of reasons why, for efficiency, it might make sense to treat lexical
entries differently from other rules, however.  We will not make these
optimizations here as they make the algorithms harder to follow.

One important way in which computers can be of use to linguists is by
allowing them to experiment with different grammars and show them
implications of the various choices they make which might be hard to
work out by hand.  A useful tool in this context is a program that can
randomly generate sentences that are judged legal by a grammar.
Notice that it would not be so useful to have a random generator built
to work only with a specific grammar, in the same way that the ATN
program developed in Chapter 2 was specific to a particular model of
English,  for the linguist would then have to get involved with
programming whenever he or she wanted to change a rule in the grammar.
Instead, we want to have a program that can accept any grammar (in
some formalism), written in a way not dissimilar to how a linguist
would write one, and randomly produce legal sentences.  In our POP-11
program (lib randgen), we will deal with CF-PSGs, represented by list
structures as above.

Here is the top-level procedure of our random generator.  The
procedure generate takes a description of the kind of phrase to be
generated (for example, [S]) and produces as its result a list of
words (for example, [Dr Chan died]):                     

    define generate(description) -> output;
       vars LHS RHS mrules;
       if isword(description) then
          [^description] -> output
       else
          matching_rules(description) -> mrules;
          if mrules /== [] then
             oneof(mrules) --> [?LHS ??RHS];
             generate_all(RHS) -> output
          else
             mishap('Cannot generate from description', [^description])
          endif
       endif
    enddefine;

Generate will be called recursively with descriptions of smaller and
smaller phrases until it is called with a single word as the
description.  In this case, the word itself, packaged in a list, is
returned as the result.  If the description is not a single word, it
must be a list representing a syntactic category; so, to generate from
it, the program must look for rules about what a phrase of this kind
can consist of.  Matching_rules returns the list of all such rules,
and one is then chosen at random using the library procedure oneof.
The RHS of this rule is extracted (the LHS, which is the same as the
original description, being ignored) and passed to generate_all.
Since the RHS of a rule is just a list of the kind of items that
generate can work from, generate_all simply calls generate on each
element, concatenating the results together:

    define generate_all(RHS);
       vars first rest;
       if RHS matches [?first ??rest] then
          generate(first) <> generate_all(rest)
       else
          []
       endif
    enddefine;

Matching_rules has to work through the grammar rules, collecting
together in a list all the ones that start with the right category.
It uses a procedure unify to compare the description it is generating
from with the LHS of the rule.  In a more general situation, where the
description and LHS may specify values of several features, unify will
have to be more complicated, as we will see.  For our current
purposes, however, it suffices for unify to test whether the two lists
are equal:

    define matching_rules(description);
       vars rule LHS RHS;
       [% for rule in rules do
              rule --> [?LHS ??RHS];
              if unify(description,LHS) then rule endif
          endfor
       %]
    enddefine;

    define unify(x, y);
       x = y
    enddefine;

This simple program works well with small grammars but would have to
be improved to work well if we had hundreds of rules.  One source of
inefficiency is the search through the whole list of rules, which is
carried out by matching_rules every time a category has to be
generated from.  If we grouped rules with the same category on the LHS
together, perhaps as follows:

    [[[S]
        [[NP] [VP]]]
      [[VP]
        [[V]]
        [[V][NP]]]
      [[NP]
        [Dr Chan]
        [MediCenter]
        [nurses]
        [patients]]
      [[V]
        [died]
        [employed]]] -> rules;

then matching_rules would only have to work through a list of groups,
rather than a list of individual rules.  Alternatively, rules could be
stored in a POP-11 property, for rapid retrieval, given the left-hand
category.

If you have just written a large phrase structure grammar, this
generation program might be useful to help you detect places where the
grammar is not strict enough in its characterization of legality.
Getting an example of an illegal sentence that can be generated is,
however, not necessarily very useful.  What we more often want to know
is how the grammar managed to generate such a monstrosity.  For this
reason, it is interesting to see whether we can generate the parse
trees of random sentences allowed by the grammar.  In fact, our
program can be altered straightforwardly to do this, the result being
called lib randtree.  In this modified program, generate returns a
single parse tree, represented as a list in the way shown earlier, and
generate_ALL returns a list of parse trees.  Here are the new
definitions (the other definitions do not need to be changed):

    define generate(description) -> tree;
       vars LHS RHS rs subtrees;
       if isword(description) then
          description -> tree
       else
          matching_rules(description) -> rs;
          if rs /== [] then
             oneof(rs) --> [?LHS ??RHS];
             generate_all(RHS) -> subtrees;
             [^(category(description)) ^^subtrees] -> tree
          else
             mishap('Cannot generate from specification', [^description])
          endif
       endif
    enddefine;

    define generate_all(RHS);
       vars first rest;
       if RHS matches [?first ??rest] then
          generate(first) :: generate_all(rest)
       else
          []
       endif
    enddefine;

    define category(description) -> c;
       description --> [?c];
    enddefine;

Notice how, now that generate returns a single item (parse tree),
rather than a sequence of items (words), the call to <> in
generate_ALL is replaced by a call to ::.

Encoding feature specifications in POP-11      

Collections of feature names and associated values are easily
represented in POP-11.  We will represent them using lists of lists,
with each sublist specifying a feature name and a value.  For
instance, the following list:

    [[person 3] [number sing]]

represents something with PERSON and NUMBER features.  The values for
these are, respectively, 3 and SING.  As before, we can represent a
grammar rule by a list consisting of the LHS category followed by the
RHS categories, these categories now being more complex than the
single-element lists used previously.  The main complication now is
that a PATR rule can state that two features must have the same value,
without specifying in advance what that value is to be.  In our
representation, where two features are required to share a value (by a
PATR '=' statement), the two values will be denoted by occurrences of
the same variable symbol.  Variable symbols need to be distinguished
from normal atomic values in some way, but apart from this only one
aspect of their form is of importance.  Where the same variable symbol
occurs several times, the appropriate values have to be the same;
where two different variable tokens appear, the values do not have to
be the same.  We have chosen to represent a variable symbol by a word
starting with '_', because this is easy to type, yet unlikely to
conflict with actual feature names or values we are likely to use.  A
PATR rule can then be translated into the POP-11 notation by
collecting up all the information provided about each given category
into a single list, using multiple occurrences of the same variable to
indicate where a value must be shared.  For instance, the Grammar4
rule:

    Rule {single complement verbs}
        VP -> V X:
            <V arg1> = <X cat>
            <VP slash> = <X slash>.

could be translated into the following in POP-11:

    [[[cat VP] [slash _x]] [[cat V] [arg1 _y]] [[cat _y] [slash _x]]]

where the variable symbol '_x' is used to indicate that the SLASH of
the VP must be the same as the SLASH of the second subphrase and the
symbol '_y' is used to indicate that the cat of the second subphrase
must be the same as the ARG1 of the verb.

The POP-11 notation makes it relatively easy to see how a single rule
using features corresponds to a number of context-free phrase
structure rules.  With the above rule, a possible CF-PSG rule can be
derived first of all by filling out the representation to mention
explicitly all possible features for all phrases.  Thus, if cat, SLASH
and ARG1 are the only possible features, then the rule is 'filled out'
to:

    [[[cat VP] [slash _x] [arg1  _v1]]
     [[cat  V] [arg1  _y] [slash _v2]]
     [[cat _y] [slash _x] [arg1  _v3]]]

where the extra variables _v1, _v2 and _v3 appear once each.  It is
now possible to consider a completely specified instance of this rule
by choosing a possible concrete value for each variable, for instance:

     _x  - NP
     _y  - NP
     _v1 - 0
     _v2 - 0
     _v3 - 0

This assignment of values to variables gives the following rule:

    [[[cat VP] [slash NP] [arg1  0]]
     [[cat  V] [arg1  NP] [slash 0]]
     [[cat NP] [slash NP] [arg1  0]]]

All we need now is a convention for translating each completely
specified feature bundle into an atomic symbol.  For instance, we
could take the cat, SLASH, and ARG1 feature values in order, separated
by _'s.  We would then have the following context-free rule:

    [[VP_NP_0] [V_0_NP] [NP_NP_0]]

Corresponding to different variable assignments, we will, of course,
get different context-free phrase structure rules out at the end.
But, as long as we are consistent about our conventions (for instance,
in translating at the end from feature bundles to symbols), the
resulting grammar will be exactly equivalent to the original one.

The top level of a POP-11 program that carries out this translation
might look like the following procedure, which prints out all the CF-
PSG rules that correspond to a give rule:

    define expand_rule(r);
       vars variable_list newrule;
       fillout_rule(r) -> newrule -> variable_list;
       subst_values(variable_list, newrule)
    enddefine;

FILLOUT_RULE produces a new rule by adding new variables, like _v1 in
the above, for unmentioned features.  It also builds a list with an
entry for each variable symbol and the list of possible values it can
have, for instance:

    [ [_x  NP S PP 0]
       [_v1 NP 0 N V PP] ]

How is it to know what possible features there are and what possible
values they can have?  The possible features, together with their
possible values, will have to be declared in a global variable:

    [  [cat   S NP VP PP AP 0 P N V]
       [slash S NP VP PP AP 0]
       [arg1  S NP VP PP AP 0]
       [empty yes no]
    ] -> features;

SUBST_VALUES is in charge of enumerating every possible concrete
instance of the rule obtainable by substituting one of the possible
values for each of the variables in the VARIABLE_LIST:

    define subst_values(variable_list, rule);
       vars name values rest v;
       if variable_list = [] then
          rule =>
       elseif variable_list matches [[?name ??values] ??rest] then
          for v in values do
             subst_values(rest, subst_value(name, v, rule))
          endfor
       endif
    enddefine;

The procedure uses recursion to carry out the enumeration of all
possibilities.  Each call of SUBST_VALUES is in charge of trying out
all possible values for the variable that occurs first in the list.
For each such value v, it calls SUBST_VALUE to actually substitute
that value for the variable and then SUBST_VALUES again to deal with
the rest of the variables.  When the recursion bottoms out, the actual
value of the rule, with values for all the variables, is printed out.
SUBST_VALUE is easily defined:

    define subst_value(name, value, thing);
       vars x;
       if thing = name then value
       elseif islist(thing) then
          [% for x in thing do subst_value(name, value, x) endfor %]
       else thing                     
       endif
    enddefine;

In Chapter 7, we will look in more detail at the semantics of feature
structures and develop POP-11 programs for more interesting
applications.
